"""
Data Service
============

â€¢ S3 â†’ ìµœì‹  1 ì‹œê°„ ì„¼ì„œ JSON(ë˜ëŠ” JSONL) â†’ DataFrame â†’ ì „ì²˜ë¦¬ â†’ ëª¨ë¸ ìž…ë ¥ìš© wide í¬ë§· ë°˜í™˜
â€¢ ë¡œê·¸ëŠ” print ëŒ€ì‹  logger ì‚¬ìš©
â€¢ ì„¤ì •â€§ìƒìˆ˜ëŠ” app.core ëª¨ë“ˆì—ì„œ ê°€ì ¸ì™€ model_service ì™€ ì»¬ëŸ¼ ì‹±í¬ ìœ ì§€
"""
from __future__ import annotations

import io
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
from typing import Optional

import boto3
import pandas as pd
from botocore.exceptions import ClientError

from app.core.config import settings                  # Pydantic BaseSettings
from app.core.constants import FEATURE_COLS           # ëª¨ë¸ í•™ìŠµ ì»¬ëŸ¼
from app.core.logging_config import get_logger

logger = get_logger("monitory.data")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# S3 í—¬í¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _get_s3_client():
    """IAM Role í˜¹ì€ Key/Secret ë°©ì‹ ë‘˜ ë‹¤ ì§€ì›"""
    if settings.AWS_ACCESS_KEY_ID and settings.AWS_SECRET_ACCESS_KEY:
        logger.debug("S3: key/secret ê¸°ë°˜ ì¸ì¦")
        return boto3.client(
            "s3",
            aws_access_key_id=settings.AWS_ACCESS_KEY_ID,
            aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,
            region_name=settings.AWS_REGION,
        )
    logger.debug("S3: IAM Role ê¸°ë°˜ ì¸ì¦")
    return boto3.client("s3", region_name=settings.AWS_REGION)


def _get_s3_key_for_input(zone_id: str, equip_id: str) -> str:
    """equipIdÂ·zoneId ê¸°ì¤€ â€˜1 ì‹œê°„ ì „â€™ ë‚ ì§œ ë””ë ‰í„°ë¦¬ ìƒì„±"""
    one_hour_ago = datetime.now(ZoneInfo("Asia/Seoul")) - timedelta(hours=1)
    date = one_hour_ago.strftime("%Y-%m-%d")
    key = f"EQUIPMENT/date={date}/zone_id={zone_id}/equip_id={equip_id}/"
    logger.info(f"âœ… S3 Key ìƒì„±: date={date}, zoneId={zone_id}, equipId={equip_id}")
    return key


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_input_data_from_s3(zone_id: str, equip_id: str) -> Optional[pd.DataFrame]:
    """
    S3ì—ì„œ ê°€ìž¥ ìµœì‹  JSON(.json / .jsonl) íŒŒì¼ì„ ì½ì–´ ì „ì²˜ë¦¬ ê²°ê³¼(DataFrame) ë°˜í™˜.
    ì‹¤íŒ¨ ì‹œ `None`.
    """
    bucket = settings.S3_INPUT_DATA_BUCKET_NAME
    prefix = _get_s3_key_for_input(zone_id, equip_id)

    if not bucket or not prefix:
        logger.error("âŒ S3 ìž…ë ¥ ë²„í‚·/í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    s3 = _get_s3_client()
    latest_key = None
    latest_time = None

    try:
        logger.info(f"ðŸ’¡ ê°ì²´ ë‚˜ì—´: s3://{bucket}/{prefix}")
        resp = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)
        if "Contents" not in resp:
            logger.error(f"âŒ ê²½ë¡œ ì—†ìŒ: s3://{bucket}/{prefix}")
            return None

        for obj in resp["Contents"]:
            key = obj["Key"]
            if key == prefix or not key.endswith(".json"):
                continue
            mod_time = obj["LastModified"]
            if latest_time is None or mod_time > latest_time:
                latest_key, latest_time = key, mod_time

        if latest_key is None:
            logger.error(f"âŒ '.json' íŒŒì¼ ì—†ìŒ: s3://{bucket}/{prefix}")
            return None

        logger.info(f"â­ï¸ ìµœì‹  íŒŒì¼: s3://{bucket}/{latest_key} (ìˆ˜ì •: {latest_time})")
        file_obj = s3.get_object(Bucket=bucket, Key=latest_key)
        content = file_obj["Body"].read().decode("utf-8")

        # JSONL â†” JSON ìžë™ íŒë³„
        if "\n" in content.strip():
            df_raw = pd.read_json(io.StringIO(content), lines=True)
        else:
            df_raw = pd.read_json(io.StringIO(content), orient="records")

        logger.info(f"ðŸ“Š ì›ë³¸ DF shape={df_raw.shape}")
        return preprocess_input_data(df_raw, window=5)

    except ClientError as e:
        logger.exception(f"ðŸš¨ S3 ClientError: {e}")
        return None
    except Exception as e:
        logger.exception(f"ðŸš¨ S3 ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì „ì²˜ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def preprocess_input_data(df: pd.DataFrame, window: int = 5) -> Optional[pd.DataFrame]:
    """
    â€¢ rolling mean/std, pivot, ì„¼ì„œ ëˆ„ë½ì»¬ëŸ¼ ë³´ì •, power_factor ìƒì„±
    â€¢ ë°˜í™˜ ì»¬ëŸ¼ = FEATURE_COLS (constants.py) ê³¼ 100% ì¼ì¹˜
    """
    if df is None or df.empty:
        logger.error("âŒ ìž…ë ¥ ë°ì´í„° ì—†ìŒ")
        return None

    logger.info("ðŸ“Š [1] ì‹œê°„ìˆœ ì •ë ¬")
    df = df.sort_values(["equipId", "sensorType", "time"])

    logger.info("ðŸ“Š [2] rolling ê³„ì‚°")
    df["val_rollmean"] = (
        df.groupby(["equipId", "sensorType"])["val"]
        .rolling(window=window, min_periods=1)
        .mean()
        .reset_index(level=[0, 1], drop=True)
    )
    df["val_rollstd"] = (
        df.groupby(["equipId", "sensorType"])["val"]
        .rolling(window=window, min_periods=1)
        .std()
        .reset_index(level=[0, 1], drop=True)
    )

    logger.info("ðŸ“Š [3] sensorType ë§¤í•‘ ë° í•„í„°ë§")
    mapping = {
        "temp": "temperature",
        "humid": "humidity",
        "pressure": "pressure",
        "vibration": "vibration",
        "reactive_power": "reactive_power",
        "active_power": "active_power",
    }
    df = df[df["sensorType"].isin(mapping.keys())]

    logger.info("ðŸ“Š [4] ê·¸ë£¹ ì§‘ê³„(mean)")
    agg = (
        df.groupby(["equipId", "sensorType"])[["val", "val_rollmean", "val_rollstd"]]
        .mean()
        .reset_index()
    )

    logger.info("ðŸ“Š [5] pivot â†’ wide")
    wide = agg.pivot(
        index=["equipId"],
        columns="sensorType",
        values=["val", "val_rollmean", "val_rollstd"],
    ).reset_index()

    logger.info("ðŸ“Š [6] ì»¬ëŸ¼ëª… í‰íƒ„í™”")
    wide.columns = [
        col[0]
        if col[0] == "equipId"
        else (
            f"{mapping[col[1]]}"
            if col[0] == "val"
            else f"{mapping[col[1]]}_{col[0].replace('val_', '')}"
        )
        for col in wide.columns
    ]
    wide = wide.rename(columns={"equipId": "equipment"})

    logger.info("ðŸ“Š [7] ëˆ„ë½ ì„¼ì„œ ì»¬ëŸ¼ ë³´ì •")
    for col in FEATURE_COLS:
        if col not in wide.columns:
            wide[col] = 0
            logger.warning(f"âš ï¸  ëˆ„ë½ ì»¬ëŸ¼ ì±„ì›€ â†’ {col}")

    logger.info("ðŸ“Š [8] power_factor ìƒì„±")
    wide["power_factor"] = (
        wide["active_power"]
        / (wide["active_power"] ** 2 + wide["reactive_power"] ** 2) ** 0.5
    ).fillna(0)

    logger.info(f"âš ï¸ power_factor ìƒì„± -> {wide['power_factor']}")

    clean_cols = ["equipment", *[c for c in FEATURE_COLS if c != "equipment"]]
    wide_clean = wide[clean_cols]

    # ðŸ‘€ ë¯¸ë¦¬ë³´ê¸° 5í–‰ë§Œ ë¡œê·¸ë¡œ ë‚¨ê¸°ê¸°
    logger.info(
        "âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! shape=%s\n%s",
        wide_clean.shape,
        wide_clean.head().to_string(index=False)
    )

    return wide_clean
